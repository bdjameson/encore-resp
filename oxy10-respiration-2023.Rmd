---
title: "Oxy10 Respiration"
author: "Brett D. Jameson"
date: "11/05/2023"
output: pdf_document
---

## Install and load required packages

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

## install packages if you dont already have them in your library
if (!require("devtools")) install.packages("devtools")
if (!require("furrr")) install.packages("furrr")
if (!require("future")) install.packages("future")
if (!require("tidyverse")) install.packages("tidyverse")
if (!require("lubridate")) install.packages("lubridate")
if (!require("cowplot")) install.packages("cowplot")
if (!require("LoLinR")) install_github('colin-olito/LoLinR') 

## load libraries
library(devtools)
library(LoLinR)
library(tidyverse)
library(lubridate)
library(cowplot)
library(data.table)
library(hms)
library(plyr)
library(dplyr)

## libraries for parallel processing
library(future)
library(furrr)
```

# Coral Respiration Data Analysis - Step 1 (Raw data processing)

This file contains code scripts for Step 1 of processing, visualization, and analysis of coral photosynthesis/respiration data obtained from the PreSens Oxy10 Respiration chamber system. Code scripts were adapted from the Putnam Lab at URI which can be found at https://github.com/hputnam/LightCurve_TPC/tree/main/RAnalysis/scripts.

## Read and combine all data files

First we need to read all of the discrete Oxy10 data files for each run and combine them with the Oxy10 incubation metadata containing the light/dark cycle times. We will start by telling R where to look for all of our data files.  

```{r}
path.p = "./data/oxy10-data-2023/oxy10-combined-data/" #the location of resp files for three-spp experiment

# List data files
file.names <- list.files(path = path.p, pattern = "csv$")  # list all csv file names in the folder
file.names <- file.names[!grepl("metadata", file.names)]   # omit metadata from files to be read in as data  # omit metadata from files to be read in as data
```

Next we will read the metadata and manipulate it into a usable table. To do this we need to combine the light and dark start/stop times into single start/stop columns with a corresponding light or dark cycle identifier column. 

```{r}
metadata <- read.csv(file="./data/oxy10-data-2023/oxy10-metadata-2023-clean.csv")

# Change metadata class to type Tibble
metadata <-as.tibble(metadata)

# Convert chamber volume to L
metadata$Chamber.vol.L <- metadata$chamber.vol/1000
#metadata$Surface_area <- metadata$Surface_area/100

# We need to manipulate the metadata table to vertically stack start/stop times for light versus dark incubations
metadata <- metadata %>% slice(rep(1:n(), each = 2))

metadata <- metadata %>% 
  dplyr::mutate(light.dark = ifelse(dplyr::row_number() %% 2 == 0, "0", "1")) %>%
  dplyr::mutate(start.time = as_hms(ifelse(row_number() %% 2 == 0, dark.start,  light.start))) %>%
  dplyr::mutate(stop.time = as_hms(ifelse(row_number() %% 2 == 0, dark.stop,  light.stop))) 
```

Now we will perform some additional wrangling of the metadata to select our relevant variables, set date classes, and select the experiment we want to work with.

```{r}
# Select only certain columns
metadata <- metadata %>% 
  mutate(date = as_date(as.character(date), format = "%Y%m%d", tz = "Atlantic"))

metadata <- metadata %>% 
  mutate(fragment.id = gsub(".*-","", colony.id)) %>%
  mutate(colony = substr(fragment.id, 1, 1)) %>%
  mutate(colony = paste(species, colony, sep="-")) %>%
  mutate(id.timep = paste(fragment.id, abbreviate(timepoint, minlength=1), sep = "-")) %>%
 # subset(experiment=="three-spp") %>% 
  dplyr::select(date, experiment, site, species, colony, colony.id, fragment.id, id.timep, surface.area, run.total,
                treatment, history, timepoint, Chamber.vol.L,date, start.time, stop.time, light.dark)
```

## Read Oxy10 data files

Next we will search the relevant directory for all of the Oxy10 data files corresponding to the given experiment. We will use the filename as the initial identifier to set the colony id column. This column will be used to match the Oxy10 data to the metadata. 

```{r, results="hide", message=FALSE}
pattern = ".*_([^_]*_[^_]*)$" # define regex pattern for colony id extraction

df <- tibble(file.name = file.names) %>%
  mutate(colony.id = gsub(pattern, "\\1", file.name)) %>% # Get colony.id from filename
  mutate(colony.id = gsub("\\..*", "", colony.id)) %>% # couldn't figure out how to do this in one regex expression
  mutate(colony.id = gsub("_", "-", colony.id)) %>%
  # we need to create a new id column to separate initial and final measurements for repeat fragments
  mutate(id.timep = if_else(grepl("20230918", file.name) | grepl("20230919", file.name) | 
                            grepl("20230925", file.name) | grepl("20230926", file.name) | 
                            grepl("20230927", file.name), 
            paste(colony.id, "I", sep="-"), paste(colony.id, "F", sep="-"))) %>%
  mutate(id.timep = gsub("^[^-]+-", "", id.timep)) %>%
  mutate(info = map(id.timep, ~filter(metadata, id.timep == .)),   # Get associated sample info
         data0 = map(file.name, ~read_csv(file.path(path.p, .), skip=1, col_types = cols(.default = "d", Time = "t"))))   # Get associated O2 data

# Select only Time, Value, and Temp columns from O2 data
df <- df %>%
  mutate(data0 = map(data0, ~dplyr::select(., Time, Value, Temp))) %>%
  mutate(data0 = map(data0, ~(.x %>% filter(complete.cases(.))))) #remove NAs to get rid of artifact line in our data
```

## Link Oxy10 data with light/dark cycles

We use the time breaks in the sample metadata (info) to link O2 data with light/dark cycles.

```{r, warning = FALSE}
df <- df %>%
  mutate(intervals = map2(data0, info, function(.x, .y) {
    split(.x, f = cut(as.numeric(.x$Time), breaks = as.numeric(c(.y$start.time, last(.y$stop.time))),
                      labels = as.character(.y$light.dark)))})) %>%
  mutate(data = map(intervals, ~ unnest(tibble(.), .id = "light.dark")))

## 'data' now contains the O2 data with the corresponding light value as another column
## Example of what 'data' for each sample looks like:
df$data[[148]]
```


# Data thinning and regression diagnostics

Next we thin the data to remove some data points. Then we will select a colony to view a comparison of the thinned datasets versus thinned datasets.

```{r, fig.height = 8, fig.width = 8}
# Set thinning parameter
thin_par <- 20

# Thin data for all samples
df <- df %>%
  mutate(thin_data = map(data, ~ slice(., seq(1, nrow(.), thin_par))))

# Create plots for full dataset and thinned data
df <- df %>%
  mutate(data_plot = map2(data, id.timep, ~ ggplot(.x, aes(x = Time, y = Value)) + 
                            facet_wrap(~ as.numeric(light.dark), scales = "free") +
                            geom_point() +
                            labs(title = .y)),
    thin_data_plot = map2(thin_data, id.timep, ~ ggplot(.x, aes(x = Time, y = Value)) + 
                            facet_wrap(~ as.numeric(light.dark), scales = "free") +
                            geom_point() +
                            labs(title = .y)))

# Example of plots
cowplot::plot_grid(df$data_plot[[152]], df$thin_data_plot[[152]], nrow = 2,
                   labels = c("Example plot: all data", "Example plot: thinned data"))
```

The full or thinned data plot for any sample can be accessed like this:

```{r Plot data for individual colonies}
df %>%
  filter(id.timep == "A0487-F") %>%
  pull(thin_data_plot)
```

## Fit linear regressions to light and dark intervals

The 'LolinR' package is called here to fit a series of linear regressions to each light/dark interval. This allows us to remove noise and select the best model for the linear range of each experiment.

```{r Regression model fitting}
# Define function for fitting LoLinR regressions to be applied to all intervals for all samples
fit_reg <- function(df) {
  rankLocReg(xall = as.numeric(df$Time), yall = df$Value, 
             alpha = 0.2, method = "pc", verbose = FALSE)
}

# Setup for parallel processing
future::plan(multisession)

# Map LoLinR function onto all intervals of each sample's thinned dataset
df <- df %>%
  mutate(regs = furrr::future_map(thin_data, function(.) {       # future_map executes function in parallel
    group_by(., light.dark) %>%
    do(rankLcRg = fit_reg(.))
  }))

## Now 'regs' contains the fitted local regressions for each interval of each sample's thinned dataset

# Define function to pull out and plot regression diagnostics
plot_rankLcRg <- function(id.timep, interval_number) {
  df %>%
    filter(id.timep == id.timep) %>%
    pluck("regs", 1, "rankLcRg", interval_number) %>%
    plot()
}
```

The diagnostics for any regression can be plotted like this, specifying a colony_id and the number of the light curve interval:

```{r Regression diagnostics}
# pdf("output/Past-D1_test.pdf")
plot_rankLcRg("DLAB-D0934", 1)
plot_rankLcRg("DLAB-D0934", 2)
# dev.off()
```

### Extract slope of best regression for each interval for each sample

```{r Extract slopes}
df.out <- df %>% 
  unnest(regs) %>%
  mutate(micromol.L.s = map_dbl(rankLcRg, ~ pluck(., "allRegs", "b1", 1)))
```

### Adjust by chamber volume and normalize to surface area

```{r}
### Merge rates with sample info
pr <- left_join(
  dplyr::select(df.out, colony.id, id.timep, light.dark, micromol.L.s),
  distinct(metadata, date, experiment, site, species, colony.id, id.timep, timepoint, surface.area, run.total, 
           treatment, history, Chamber.vol.L))
```

# Correct for chamber volume and blanks
LEFT OFF HERE
```{r}
### generate a key for the blank id
pr <- pr %>%
  mutate(Run_blank_light=paste0(run.total,"_","blank","_", light.dark))%>%
  mutate(blank_id=paste0(run.total,"_","blank"))

# Get blank values -- average for each run and light value in case multiple blanks
blanks <- pr %>%
  filter(grepl("BLNK", colony.id)) %>%
  mutate(micromol.s.blank = micromol.L.s * Chamber.vol.L) %>%
  group_by(run.total, light.dark) %>%
  mutate(blank_id=paste0(run.total,"_","blank")) %>%
  mutate(Run_blank_light=paste0(run.total,"_","blank","_",light.dark)) 

blanks %>% ggplot(aes(x=as.factor(light.dark), y=micromol.s.blank,colour = as.factor(run.total)))+
  geom_point()

mean.blank <- blanks %>%
 ungroup(run.total, light.dark) %>%
 summarise(mean = mean(micromol.s.blank))

str(summary(lm(blanks$micromol.s.blank~as.numeric(blanks$light.dark))))
anova(lm(blanks$micromol.s.blank~as.numeric(blanks$light.dark)))

# specific.blanks <- read_csv(file = "data/1_pi_curves/blank_groups.csv")
# blanks <-  left_join(blanks,specific.blanks, keep=F)

pr <- pr %>% mutate(micromol.s = micromol.L.s * Chamber.vol.L)

blanks <- blanks %>% ungroup() %>% select(Run_blank_light, blank_id, micromol.s.blank)
pr <-  left_join(pr, blanks, by="Run_blank_light", keep=FALSE) 

#Join blank values with rest of data and subtract values from samples for same run and light value
pr <- pr %>%
  mutate(micromol.s.adj = micromol.s - micromol.s.blank) %>% # using mean blank value
  # After correcting for blank values, remove blanks from data
  filter(!grepl("BLNK", colony.id))

## Residual code from Putnam Lab scripts
# pr  <- pr  %>%
#   rename(colony_id = colony_id.x)
# 
# pr  <- pr  %>%
#   rename(Light_Value = Light_Value.x)

# Import surface area data 
#sa <- read.csv("output/1_surface_area.csv") # NEED UPDATED SA DATA

# Join surface area with rest of data
# pr <- left_join(pr, select(sa, colony_id, surface.area.cm2)) # COMMENTED OUT UNTIL SA DATA AVAILABLE


# Normalize rates by surface area
#pr <- pr %>%
#  mutate(micromol.cm2.s = micromol.s.adj / surface.area.cm2,
#         micromol.cm2.h = micromol.cm2.s * 3600)

# Divide by ten for surface area until data is available
pr <- pr %>%
  mutate(micromol.cm2.s = micromol.s.adj / as.numeric(surface.area), # initially character string for some reason
         micromol.cm2.h = micromol.cm2.s * 3600)
```

# Write to output file
```{r Write calculated rates to output file}
# Select variables to write to file
pr.out <- pr %>% subset(experiment == "three-spp") %>%
  dplyr::select(date, experiment, site, species, colony.id, id.timep, light.dark, run.total, treatment, history,
                timepoint, micromol.cm2.s, micromol.cm2.h) 

# Write to output file
write.csv(pr.out, "output/three-spp-2023.csv")
```


